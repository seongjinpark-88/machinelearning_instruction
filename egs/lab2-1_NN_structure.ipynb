{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understand the structure of perceptron/neural nets\n",
    "\n",
    "**Note:** 이 `notebook`을 실행하기 전에 다음과 같은 내용을 먼저 알아보겠습니다.\n",
    " 1. `OR` question\n",
    " 2. Perceptron and Neural Nets\n",
    " \n",
    " \n",
    "이번 노트북에서는 `keras`를 사용하지 않고, `numpy`를 위주로 사용하여서 `perceptron` 및 `neural nets`의 구조를 살펴보겠습니다. 이 `notebook`의 목적은 실제 모델이 학습과정에서 어떻게 `weight`와 `bias`를 수정하고, 어떻게 주어진 값을 통해서 결과값을 예측하는지 이해하는 것입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python notebook for Make Your Own Neural Network\n",
    "# code for a 3-layer neural network, and code for learning the MNIST dataset\n",
    "# (c) Tariq Rashid, 2016\n",
    "# license is GPLv2\n",
    "\n",
    "# Modified: Seongjin Park (seongjinpark@email.arizona.edu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "# scipy.special for the sigmoid function expit()\n",
    "import scipy.special\n",
    "# library for plotting arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model structure\n",
    "\n",
    "`python`에서 `class`의 개념은 이해하지 못하셔도 좋습니다. 하지만 아래의 모델이 어떠한 구조로 이루어져 있는지는 이해하셔야 합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network class definition\n",
    "class neuralNetwork:\n",
    "    \n",
    "    \n",
    "    # initialise the neural network\n",
    "    def __init__(self, inputnodes, outputnodes, learningrate):\n",
    "        # set number of nodes in each input, hidden, output layer\n",
    "        self.inodes = inputnodes\n",
    "        self.onodes = outputnodes\n",
    "        \n",
    "        # link weight matrices, wih and who\n",
    "        # weights inside the arrays are w_i_j, where link is from node i to node j in the next layer\n",
    "        # w11 w21\n",
    "        # w12 w22 etc \n",
    "        self.wio = numpy.random.normal(0.0, pow(self.inodes, -0.5), (self.onodes, self.inodes))\n",
    "\n",
    "        # learning rate\n",
    "        self.lr = learningrate\n",
    "        \n",
    "        # activation function is the sigmoid function\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        \n",
    "        pass\n",
    "\n",
    "    \n",
    "    # train the neural network\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        targets = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.wio, inputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        # output layer error is the (target - actual)\n",
    "        output_errors = targets - final_outputs\n",
    "        \n",
    "        # update the weights for the links between the hidden and output layers\n",
    "        self.wio += self.lr * numpy.dot((output_errors * final_outputs * (1.0 - final_outputs)), numpy.transpose(inputs))     \n",
    "        \n",
    "        pass\n",
    "\n",
    "    \n",
    "    # query the neural network\n",
    "    def query(self, inputs_list):\n",
    "        # convert inputs list to 2d array\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.wio, inputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "        return final_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "간단한 모델을 구성하여서 그 결과를 살펴보도록 하겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of input, hidden and output nodes\n",
    "input_nodes = 3\n",
    "output_nodes = 3\n",
    "\n",
    "# learning rate is 0.3\n",
    "learning_rate = 0.3\n",
    "\n",
    "# create instance of neural network\n",
    "n = neuralNetwork(input_nodes, output_nodes, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델에 입력값을 주었을 경우, 그 예측값이 어떻게 나타나는지 살펴보겠습니다. \n",
    "\n",
    "**Note:** 아래 셀은 실행할 때마다 값이 바뀔 것입니다. 그 이유는 학습이 이루어지지 않은 모델을 이용해서 `query`를 수행하기 때문입니다. 모델에서 `__init__` 아래에 정의되어있는 **numpy.random.normal()** 명령어에서 정규분포에 따라 무작위의 값을 생성하여 `weight`로 사용하기 때문에, 값은 매번 바뀔 것입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36402664],\n",
       "       [0.08701169],\n",
       "       [0.27530904]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test query (doesn't mean anything useful yet)\n",
    "n.query([1.0, 0.5, -1.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `OR` question\n",
    "\n",
    "`OR` 기능은 다음과 같이 정의할 수 있습니다. \n",
    " - 두 개의 값 중에 하나라도 참이면 결과는 참이다.\n",
    " \n",
    "과연 그렇다면 `OR`의 기능을 수행할 수 있는 모델을 구축 가능할지 확인해보도록 하겠습니다. \n",
    "\n",
    "먼저 입력값과 출력값을 담고 있는 `numpy` 행렬을 만들어 보도록 하겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = [[0., 0.],\n",
    "          [0., 1.],\n",
    "          [1., 0.],\n",
    "          [1., 1.]]\n",
    "\n",
    "y_data = [[0.],\n",
    "          [1.],\n",
    "          [1.],\n",
    "          [1.]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두 개의 입력값과 하나의 출력값을 갖는 모델을 생성하겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = neuralNetwork(2, 1, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "생성한 모델을 학습해보도록 하겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:\t 0\n",
      "Weights:\t [[ 0.55324479 -0.36925021]]\n",
      "Epoch:\t 1\n",
      "Weights:\t [[ 0.57280171 -0.34386746]]\n",
      "Epoch:\t 2\n",
      "Weights:\t [[ 0.59188125 -0.31889768]]\n",
      "Epoch:\t 3\n",
      "Weights:\t [[ 0.6104885  -0.29434449]]\n",
      "Epoch:\t 4\n",
      "Weights:\t [[ 0.62862999 -0.27020963]]\n",
      "Epoch:\t 5\n",
      "Weights:\t [[ 0.64631353 -0.24649321]]\n",
      "Epoch:\t 6\n",
      "Weights:\t [[ 0.66354794 -0.22319386]]\n",
      "Epoch:\t 7\n",
      "Weights:\t [[ 0.68034293 -0.20030892]]\n",
      "Epoch:\t 8\n",
      "Weights:\t [[ 0.6967089  -0.17783463]]\n",
      "Epoch:\t 9\n",
      "Weights:\t [[ 0.71265679 -0.15576626]]\n",
      "Epoch:\t 10\n",
      "Weights:\t [[ 0.72819793 -0.1340983 ]]\n",
      "Epoch:\t 11\n",
      "Weights:\t [[ 0.74334394 -0.11282457]]\n",
      "Epoch:\t 12\n",
      "Weights:\t [[ 0.7581066  -0.09193831]]\n",
      "Epoch:\t 13\n",
      "Weights:\t [[ 0.77249775 -0.07143236]]\n",
      "Epoch:\t 14\n",
      "Weights:\t [[ 0.78652925 -0.05129923]]\n",
      "Epoch:\t 15\n",
      "Weights:\t [[ 0.80021286 -0.03153113]]\n",
      "Epoch:\t 16\n",
      "Weights:\t [[ 0.81356018 -0.01212015]]\n",
      "Epoch:\t 17\n",
      "Weights:\t [[0.82658266 0.00694178]]\n",
      "Epoch:\t 18\n",
      "Weights:\t [[0.83929151 0.02566276]]\n",
      "Epoch:\t 19\n",
      "Weights:\t [[0.85169767 0.04405091]]\n",
      "Epoch:\t 20\n",
      "Weights:\t [[0.86381181 0.0621143 ]]\n",
      "Epoch:\t 21\n",
      "Weights:\t [[0.87564431 0.07986097]]\n",
      "Epoch:\t 22\n",
      "Weights:\t [[0.8872052  0.09729884]]\n",
      "Epoch:\t 23\n",
      "Weights:\t [[0.89850423 0.11443571]]\n",
      "Epoch:\t 24\n",
      "Weights:\t [[0.9095508  0.13127927]]\n",
      "Epoch:\t 25\n",
      "Weights:\t [[0.92035398 0.14783703]]\n",
      "Epoch:\t 26\n",
      "Weights:\t [[0.93092251 0.16411638]]\n",
      "Epoch:\t 27\n",
      "Weights:\t [[0.94126483 0.18012449]]\n",
      "Epoch:\t 28\n",
      "Weights:\t [[0.95138902 0.1958684 ]]\n",
      "Epoch:\t 29\n",
      "Weights:\t [[0.96130287 0.21135493]]\n",
      "Epoch:\t 30\n",
      "Weights:\t [[0.97101386 0.22659076]]\n",
      "Epoch:\t 31\n",
      "Weights:\t [[0.98052917 0.24158234]]\n",
      "Epoch:\t 32\n",
      "Weights:\t [[0.98985569 0.25633597]]\n",
      "Epoch:\t 33\n",
      "Weights:\t [[0.99900002 0.27085776]]\n",
      "Epoch:\t 34\n",
      "Weights:\t [[1.0079685  0.28515364]]\n",
      "Epoch:\t 35\n",
      "Weights:\t [[1.01676721 0.29922934]]\n",
      "Epoch:\t 36\n",
      "Weights:\t [[1.02540196 0.31309045]]\n",
      "Epoch:\t 37\n",
      "Weights:\t [[1.03387834 0.32674237]]\n",
      "Epoch:\t 38\n",
      "Weights:\t [[1.04220168 0.34019034]]\n",
      "Epoch:\t 39\n",
      "Weights:\t [[1.05037713 0.35343943]]\n",
      "Epoch:\t 40\n",
      "Weights:\t [[1.05840958 0.36649454]]\n",
      "Epoch:\t 41\n",
      "Weights:\t [[1.06630374 0.37936046]]\n",
      "Epoch:\t 42\n",
      "Weights:\t [[1.07406412 0.39204178]]\n",
      "Epoch:\t 43\n",
      "Weights:\t [[1.08169504 0.40454297]]\n",
      "Epoch:\t 44\n",
      "Weights:\t [[1.08920065 0.41686837]]\n",
      "Epoch:\t 45\n",
      "Weights:\t [[1.09658491 0.42902216]]\n",
      "Epoch:\t 46\n",
      "Weights:\t [[1.10385164 0.44100839]]\n",
      "Epoch:\t 47\n",
      "Weights:\t [[1.11100449 0.45283101]]\n",
      "Epoch:\t 48\n",
      "Weights:\t [[1.11804695 0.46449383]]\n",
      "Epoch:\t 49\n",
      "Weights:\t [[1.1249824  0.47600053]]\n",
      "Epoch:\t 50\n",
      "Weights:\t [[1.13181406 0.4873547 ]]\n",
      "Epoch:\t 51\n",
      "Weights:\t [[1.13854502 0.49855979]]\n",
      "Epoch:\t 52\n",
      "Weights:\t [[1.14517826 0.50961919]]\n",
      "Epoch:\t 53\n",
      "Weights:\t [[1.15171663 0.52053613]]\n",
      "Epoch:\t 54\n",
      "Weights:\t [[1.15816288 0.53131379]]\n",
      "Epoch:\t 55\n",
      "Weights:\t [[1.16451963 0.54195523]]\n",
      "Epoch:\t 56\n",
      "Weights:\t [[1.17078942 0.55246342]]\n",
      "Epoch:\t 57\n",
      "Weights:\t [[1.17697469 0.56284124]]\n",
      "Epoch:\t 58\n",
      "Weights:\t [[1.18307778 0.57309151]]\n",
      "Epoch:\t 59\n",
      "Weights:\t [[1.18910093 0.58321692]]\n",
      "Epoch:\t 60\n",
      "Weights:\t [[1.19504631 0.59322013]]\n",
      "Epoch:\t 61\n",
      "Weights:\t [[1.20091601 0.60310368]]\n",
      "Epoch:\t 62\n",
      "Weights:\t [[1.20671204 0.61287008]]\n",
      "Epoch:\t 63\n",
      "Weights:\t [[1.21243633 0.62252172]]\n",
      "Epoch:\t 64\n",
      "Weights:\t [[1.21809074 0.63206097]]\n",
      "Epoch:\t 65\n",
      "Weights:\t [[1.22367706 0.6414901 ]]\n",
      "Epoch:\t 66\n",
      "Weights:\t [[1.22919703 0.65081132]]\n",
      "Epoch:\t 67\n",
      "Weights:\t [[1.23465231 0.6600268 ]]\n",
      "Epoch:\t 68\n",
      "Weights:\t [[1.24004451 0.66913862]]\n",
      "Epoch:\t 69\n",
      "Weights:\t [[1.24537517 0.67814882]]\n",
      "Epoch:\t 70\n",
      "Weights:\t [[1.25064581 0.68705939]]\n",
      "Epoch:\t 71\n",
      "Weights:\t [[1.25585786 0.69587226]]\n",
      "Epoch:\t 72\n",
      "Weights:\t [[1.26101271 0.70458929]]\n",
      "Epoch:\t 73\n",
      "Weights:\t [[1.26611172 0.71321232]]\n",
      "Epoch:\t 74\n",
      "Weights:\t [[1.27115619 0.72174312]]\n",
      "Epoch:\t 75\n",
      "Weights:\t [[1.27614736 0.73018343]]\n",
      "Epoch:\t 76\n",
      "Weights:\t [[1.28108647 0.73853493]]\n",
      "Epoch:\t 77\n",
      "Weights:\t [[1.28597468 0.74679925]]\n",
      "Epoch:\t 78\n",
      "Weights:\t [[1.29081313 0.754978  ]]\n",
      "Epoch:\t 79\n",
      "Weights:\t [[1.29560292 0.76307275]]\n",
      "Epoch:\t 80\n",
      "Weights:\t [[1.30034512 0.771085  ]]\n",
      "Epoch:\t 81\n",
      "Weights:\t [[1.30504075 0.77901623]]\n",
      "Epoch:\t 82\n",
      "Weights:\t [[1.30969081 0.7868679 ]]\n",
      "Epoch:\t 83\n",
      "Weights:\t [[1.31429628 0.7946414 ]]\n",
      "Epoch:\t 84\n",
      "Weights:\t [[1.31885808 0.80233811]]\n",
      "Epoch:\t 85\n",
      "Weights:\t [[1.32337712 0.80995936]]\n",
      "Epoch:\t 86\n",
      "Weights:\t [[1.32785427 0.81750647]]\n",
      "Epoch:\t 87\n",
      "Weights:\t [[1.33229041 0.82498071]]\n",
      "Epoch:\t 88\n",
      "Weights:\t [[1.33668634 0.83238332]]\n",
      "Epoch:\t 89\n",
      "Weights:\t [[1.34104287 0.83971552]]\n",
      "Epoch:\t 90\n",
      "Weights:\t [[1.34536078 0.84697848]]\n",
      "Epoch:\t 91\n",
      "Weights:\t [[1.34964082 0.85417337]]\n",
      "Epoch:\t 92\n",
      "Weights:\t [[1.35388373 0.86130132]]\n",
      "Epoch:\t 93\n",
      "Weights:\t [[1.35809021 0.86836342]]\n",
      "Epoch:\t 94\n",
      "Weights:\t [[1.36226096 0.87536077]]\n",
      "Epoch:\t 95\n",
      "Weights:\t [[1.36639665 0.8822944 ]]\n",
      "Epoch:\t 96\n",
      "Weights:\t [[1.37049794 0.88916536]]\n",
      "Epoch:\t 97\n",
      "Weights:\t [[1.37456544 0.89597464]]\n",
      "Epoch:\t 98\n",
      "Weights:\t [[1.37859979 0.90272323]]\n",
      "Epoch:\t 99\n",
      "Weights:\t [[1.38260158 0.9094121 ]]\n"
     ]
    }
   ],
   "source": [
    "# train the neural networki\n",
    "\n",
    "# epochs is the number of times the training data set is used for training\n",
    "epochs = 100\n",
    "\n",
    "for e in range(epochs):\n",
    "    # go through all records in the training data set\n",
    "    for i in range(0,len(X_data)):\n",
    "        \n",
    "        # Set input\n",
    "        inputs = X_data[i]\n",
    "        # Set output\n",
    "        targets = y_data[i]\n",
    "        \n",
    "        model.train(inputs, targets)\n",
    "        \n",
    "        \n",
    "        pass\n",
    "    print(\"Epoch:\\t\", e)\n",
    "    print(\"Weights:\\t\", model.wio)\n",
    "        \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "실제 모델이 두 개의 입력을 받았을 때, `OR` 기능에 해당하는 예측을 할 수 있는지 확인해보겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0] \t [[0.5]] \t [0.0]\n",
      "[0.0, 1.0] \t [[0.71287984]] \t [1.0]\n",
      "[1.0, 0.0] \t [[0.7994085]] \t [1.0]\n",
      "[1.0, 1.0] \t [[0.90821345]] \t [1.0]\n"
     ]
    }
   ],
   "source": [
    "for j in range(0, len(X_data)):\n",
    "    # correct answer is first value\n",
    "    correct_label = y_data[j]\n",
    "    # scale and shift the inputs\n",
    "    inputs = X_data[j]\n",
    "    # query the network\n",
    "    outputs = model.query(inputs)\n",
    "    # the index of the highest value corresponds to the label\n",
    "    if (outputs > 0.5):\n",
    "        label = 1\n",
    "    else:\n",
    "        label = 0\n",
    "               \n",
    "    print(inputs, \"\\t\", outputs, \"\\t\", correct_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

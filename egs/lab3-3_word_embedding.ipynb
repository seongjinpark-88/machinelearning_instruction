{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding\n",
    "\n",
    "이전 많은 과정에서 살펴본 것처럼, `신경망 모델(Neural Networks)`에서는 입력값과 출력값으로 글자/문자열 대신에 실수값을 사용하는 것을 알 수 있습니다. **`word embedding`** 은 전산언어학/자연언어처리(*natural language processing/computational linguistics*)에서 사용하는 방법으로, 각각의 단어/구를 숫자로 구성된 벡터로 변경하는 것을 의미합니다. 주로 `전산 의미론(computational semantics)` 분야에서 많이 사용되는 방법이지만, 품사 태깅 (P.O.S. tagging)이나 자동 문장 파싱에서도 사용됩니다. \n",
    "\n",
    "가장 쉽게 **`word embedding`** 을 구성하는 방법은 모든 단어를 **one-hot encoding**으로 만드는 것입니다. 즉, one-hot encoding의 길이는 단어의 수와 같을 것이며, 해당 단어에 해당하는 인덱스의 숫자만 **1**로 나타나고 나머지는 **0**으로 나타내는 방법입니다. \n",
    "\n",
    "하지만 **one-hot encoding**이 널리 사용되지 않는 이유는 단어간의 유사성을 표현할 방법이 없다는 것입니다. 전체 단어 중, 서로간의 유사성이 높은 단어들이 있을 수 있고 낮은 단어들이 있을 수 있습니다. 벡터값의 유사도는 내적(`dot product`)를 사용하여서 계산을 하는데, one-hot encoding은 **0**으로 나타난 값이 많기 때문에, 곱의 결과는 항상 0이 될 것입니다. \n",
    "\n",
    "이러한 한계를 극복하기 위해서, `word embedding` 대신에 문장/텍스트의 벡터를 계산하는 방법을 선택하였습니다. 주로 사용된 방법은 **TF-IDF(Term Frequency-Inverse Document Frequency)** 와 **LSA(Latent Semantic Analysis)** 등이 있습니다. 대부분의 경우는 문장/텍스트에 해당 단어/구가 몇 번 등장하는지 그 빈도를 이용하여 문장/텍스트의 벡터를 계산한 것이며, 문장/텍스트간 의미론적 유사성을 나타냅니다. \n",
    "\n",
    "`word embedding`은 문장/텍스트가 아닌 단어를 사용한다는 점에서, 사람이 이해할 수 있는 관점에서의 의미론적 유사성을 보여줍니다. word embedding을 이용하여서 문장/텍스트의 내용을 벡터로 전환할 수 있으며, 이를 이용하여 텍스트 분류, 품사 태깅, 감성 분석등과 같은 작업들을 효과적으로 수행할 수 있음을 많은 연구들에서 보였습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec\n",
    "\n",
    "**`word2vec`** 은 현재 가장 널리 쓰이는 `word embedding`을 구현하는 방법 중 하나입니다. **word2vec**은 `분산 표현(distributed representation)`에 그 기반을 두고 있으며, 의미적으로 유사도가 높은 단어들은 문맥상 같이 등장할 것이라는 것을 전제로 합니다. \n",
    "\n",
    "다음과 같은 문장을 보겠습니다. \n",
    "\n",
    " - 서울은 한국의 수도다.\n",
    " - 도쿄는 일본의 수도다.\n",
    "\n",
    "*수도* 라는 개념이 없다고 하더라도, 의미적으로 유사도가 높은 단어들이 문맥상 같이 등장할 것이라는 것을 전제로 한다면, (서울, 한국)의 관계와 (도쿄, 일본)의 관계가 유사할 것이라고 볼 수 있을 것입니다. 결국 `word2vec`은 이러한 방법을 이용하여서 각 단어를 벡터로 변환한 이후, 단어간의 관계를 나타낼 수 있는 방법을 찾는 것이라고 볼 수 있습니다. 위의 문장을 예로 볼 때, *서울 - 한국*과 *도쿄 - 일본*의 값은 최대한 유사하여야 한다는 것입니다. \n",
    "\n",
    "`word2vec`은 위의 내용을 바탕으로 2013년에 구글 연구원 팀에서 만들어낸 모델입니다. word2vec은 텍스트를 입력받아 각 단어의 vector representation을 구하는 것입니다. 일반적으로 단어 전체 갯수를 필요로 하는 one-hot encoding보다 크기가 작으며, 공간 내부의 밀도는 더욱 높습니다. \n",
    "\n",
    "`word2vec` 모델은 두 가지 방법으로 생성될 수 있습니다. \n",
    " \n",
    " 1. CBOW(Continuous bag of words) 모델은 주변 단어를 이용하여서 현재 단어를 예측하는 방법입니다. 즉, window-size를 주었을 때, 그 사이즈에서 주어진 주변 단어를 이용하여서 어떤 단어가 나타날지 예측하는 것입니다.\n",
    " \n",
    " 2. Skip-gram 모델은 중심 단어를 이용하여서 주변 단어를 예측하는 방법입니다. 즉, window-size를 주었을 때, 그 사이즈의 중심에 있는 단어를 이용하여 그 주변에 나타날 단어들을 예측하는 것입니다. \n",
    " \n",
    "어떠한 모델이 더 성능이 좋은지 단정적으로 이야기하기는 어렵습니다. 하지만 **CBOW** 모델이 학습 속도가 더 빠르고 자주 나오지 않는 단어를 더 잘 예측하며, **Skip-gram** 모델은 한 단어의 벡터값이 더 자주 업데이터되기 때문에 데이터양이 충분할 경우 더욱 정교한 `word2vec` 모델을 만들 수 있다고 알려져있습니다. \n",
    "\n",
    "흥미로운 점은 `word2vec`이 `신경망 모델`에서 주로 이용됨에도 불구하고, 얕은 신경망구조로 만들어진다는 것입니다. \n",
    "\n",
    "이번 워크샵에서는 `word2vec`을 이용하여 간단한 텍스트 분류 및 감성 분석 작업을 진행할 것입니다. 실제 `keras` 코드를 작성하여서 `word2vec` 모델을 구현할 수도 있지만, `gensim`이라는 `python` 패키지를 사용하면 쉽게 word2vec 모델을 구현할 수 있습니다. 이번 워크샵에서 실제 `word2vec` 모델을 만드는 방법은 다루지 않을 것입니다. `gensim`을 이용한 `word2vec` 모델 생성 방법은 [이 곳](https://jusonn.github.io/blog/2018/04/24/gensim-word2vec-embedding/)을 참고하시면 좋을 것 같습니다. \n",
    "\n",
    "실제로 `word2vec`을 구성할 수도 있지만, Google에서는 이미 대용량의 데이터를 사용하여 구축한 `word2vec` 모델을 제공하고 있습니다 (https://code.google.com/archive/p/word2vec/). 모델은 `data` 폴더에 들어있습니다. 모델을 다운받은 이후 `gensim` 패키지를 사용하여서 직접 이용해볼 수 있습니다. 아래에서 `Google word2vec` 모델을 살펴보도록 하겠습니다. \n",
    "\n",
    "**Note:** Google word2vec에는 벡터값이 존재하지 않는 단어들이 있습니다. (*e.g.,* stop words) 그러므로 실제 사용할 때에는 그러한 단어들을 처리할 수 있는 방법을 생각해보아야합니다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google word2vec\n",
    "\n",
    "해당 파일이 제대로 존재하는지 확인해보겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11-0.txt\n",
      "GoogleNews-vectors-negative300.bin\n",
      "OR.txt\n",
      "XOR.txt\n",
      "cmudict-0.7b.txt\n",
      "liquid_regression.txt\n",
      "massaged_cmudict,txt\n",
      "massaged_cmudict.txt\n",
      "rhythm.txt\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GoogleNews-vectors-negative300.bin** 이라는 파일이 존재하는 것을 확인하실 수 있습니다. 해당 파일은 Google에서 뉴스 데이터를 이용하여 300개의 값을 이용한 word2vec 모델을 만들어 둔 것입니다. \n",
    "\n",
    "`gensim` 패키지를 불러온 이후, `word2vec` 모델도 불러오겠습니다. \n",
    "\n",
    "**Note:** Google에서 생성한 word2vec은 모델 크기가 크기 때문에 불러오는데 시간이 조금 걸립니다. 그리고 *C binary* 포맷으로 작성되었기 때문에 **binary=True**를 입력하여야 합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format(\"data/GoogleNews-vectors-negative300.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "불러온 모델에 어떤 단어들이 있는지 보고, 특정 단어의 실제 **embedding**을 출력해보겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bullying_cyberbullying',\n",
       " 'Laurent_Garnier',\n",
       " 'Conecuh',\n",
       " 'Headlee_Amendment_override',\n",
       " 'Lagomarcino',\n",
       " 'Optical_Fiber_Cable',\n",
       " 'TRIPOLI_UNITED_NATIONS',\n",
       " 'Forensic_pathologist_Cyril_Wecht',\n",
       " 'La_Colosa',\n",
       " 'Limited_JSPL']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.vocab.keys())[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.15332031, -0.03979492,  0.16796875,  0.31445312, -0.0279541 ,\n",
       "        0.31054688,  0.26367188, -0.12988281,  0.19628906, -0.11474609,\n",
       "        0.28320312, -0.06640625, -0.38671875,  0.17382812, -0.1875    ,\n",
       "       -0.09667969,  0.14355469,  0.26757812,  0.22558594, -0.26367188,\n",
       "       -0.28710938,  0.38867188, -0.03149414, -0.33789062, -0.02197266,\n",
       "       -0.20507812, -0.03662109, -0.13671875, -0.14160156,  0.03417969,\n",
       "        0.1796875 ,  0.1875    , -0.16894531,  0.12402344, -0.1015625 ,\n",
       "       -0.13671875, -0.05566406,  0.45703125, -0.03198242, -0.05664062,\n",
       "       -0.0189209 , -0.06640625,  0.10791016,  0.33203125, -0.3203125 ,\n",
       "       -0.16113281, -0.14257812, -0.265625  , -0.11572266,  0.39648438,\n",
       "       -0.24902344, -0.14453125, -0.01226807, -0.078125  , -0.11962891,\n",
       "        0.32226562, -0.30273438, -0.15917969,  0.24609375, -0.48046875,\n",
       "       -0.01068115, -0.140625  ,  0.3125    , -0.21679688, -0.15234375,\n",
       "       -0.10302734, -0.13378906,  0.18164062, -0.21289062, -0.30078125,\n",
       "       -0.08251953, -0.08642578, -0.0324707 , -0.04272461, -0.0480957 ,\n",
       "        0.23242188, -0.03125   ,  0.31835938,  0.06201172, -0.375     ,\n",
       "        0.04907227,  0.22558594,  0.12792969, -0.02160645, -0.13867188,\n",
       "       -0.27734375,  0.17871094,  0.18164062, -0.06738281,  0.21191406,\n",
       "       -0.21777344, -0.31640625, -0.38671875, -0.0378418 ,  0.16699219,\n",
       "        0.03320312,  0.32226562, -0.09179688, -0.18066406, -0.15722656,\n",
       "       -0.32226562, -0.12695312, -0.14941406, -0.04418945,  0.18164062,\n",
       "       -0.07421875, -0.13769531,  0.01202393,  0.04711914, -0.2734375 ,\n",
       "       -0.23730469,  0.0055542 ,  0.30664062,  0.03979492,  0.01843262,\n",
       "        0.16113281, -0.26367188,  0.05834961,  0.23144531,  0.12353516,\n",
       "       -0.11035156,  0.19726562,  0.08496094,  0.33203125, -0.15917969,\n",
       "        0.203125  , -0.21582031, -0.07910156, -0.25976562,  0.12451172,\n",
       "        0.04077148, -0.33203125, -0.41015625, -0.10400391, -0.0065918 ,\n",
       "        0.23046875, -0.05493164, -0.02539062, -0.5546875 ,  0.01745605,\n",
       "        0.15917969, -0.13769531, -0.08984375,  0.18457031, -0.10888672,\n",
       "        0.09375   , -0.0189209 ,  0.33203125, -0.10742188, -0.07861328,\n",
       "        0.44726562, -0.00067902, -0.24414062,  0.13964844, -0.01312256,\n",
       "       -0.14746094, -0.01531982,  0.17285156,  0.01757812, -0.31640625,\n",
       "       -0.04467773,  0.04907227,  0.16503906,  0.16699219,  0.12988281,\n",
       "        0.19140625,  0.25976562, -0.37695312,  0.05493164, -0.03662109,\n",
       "        0.2421875 ,  0.28125   , -0.04663086,  0.11572266,  0.4296875 ,\n",
       "        0.12988281,  0.1015625 , -0.25195312, -0.13476562, -0.11669922,\n",
       "        0.06933594,  0.15039062, -0.16699219, -0.16503906,  0.06982422,\n",
       "        0.29492188,  0.17089844, -0.12890625, -0.13378906, -0.15722656,\n",
       "        0.10742188, -0.14941406, -0.08349609,  0.09228516,  0.04931641,\n",
       "        0.47851562, -0.0291748 , -0.30664062, -0.35351562,  0.10058594,\n",
       "       -0.23535156, -0.12451172,  0.10302734,  0.0255127 , -0.1015625 ,\n",
       "       -0.23535156,  0.1796875 , -0.06933594, -0.125     ,  0.12695312,\n",
       "        0.0050354 , -0.30078125, -0.07275391, -0.15332031,  0.09130859,\n",
       "        0.140625  ,  0.06445312, -0.05688477,  0.2265625 , -0.15234375,\n",
       "       -0.20898438, -0.06982422, -0.02148438, -0.31835938,  0.2578125 ,\n",
       "       -0.10107422,  0.12988281, -0.04833984, -0.27734375,  0.03088379,\n",
       "        0.21386719, -0.06591797, -0.28710938, -0.00183868,  0.04882812,\n",
       "       -0.03491211,  0.30273438, -0.04931641,  0.02832031,  0.22167969,\n",
       "       -0.04614258, -0.04345703, -0.23828125,  0.2421875 , -0.00762939,\n",
       "        0.01251221, -0.0015564 ,  0.14648438, -0.33007812,  0.05078125,\n",
       "       -0.08251953, -0.46484375, -0.01672363,  0.42773438,  0.01348877,\n",
       "       -0.12792969, -0.12011719,  0.20507812, -0.11083984, -0.1015625 ,\n",
       "        0.44335938,  0.09765625,  0.09521484, -0.0324707 ,  0.0017395 ,\n",
       "       -0.09765625,  0.18457031, -0.25195312, -0.38671875, -0.25585938,\n",
       "       -0.0546875 , -0.0859375 , -0.27539062, -0.07324219,  0.25195312,\n",
       "        0.10009766,  0.09716797, -0.23535156, -0.16113281,  0.09960938,\n",
       "        0.11767578, -0.02087402,  0.00717163, -0.14257812,  0.05126953,\n",
       "       -0.03857422,  0.22558594,  0.13769531, -0.14453125,  0.33007812,\n",
       "       -0.1328125 , -0.14746094, -0.32226562,  0.05273438,  0.31054688,\n",
       "       -0.25585938,  0.31445312, -0.16601562,  0.31640625,  0.17382812],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[\"linguistics\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`word2vec` 모델에서 **linguistics** 라는 단어의 embedding을 출력해보았습니다. *numpy*에 있는 *shape()* 명령어를 이용하여서 300개의 숫자를 이용하여 단어를 표현하였음을 확인할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.shape(model[\"linguistics\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`gensim` 패키지를 이용하면 특정 단어와 유사한 단어들도 아래와 같이 찾아볼 수 있습니다. \n",
    "\n",
    "**Note:** 단어 벡터간 내적값을 계산하는 과정이 포함되어 있으므로 시간이 조금 걸릴 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('anthropology', 0.6730363368988037),\n",
       " ('sociology', 0.6510323286056519),\n",
       " ('Linguistics', 0.643831729888916),\n",
       " ('comparative_literature', 0.640203595161438),\n",
       " ('cultural_anthropology', 0.6203723549842834),\n",
       " ('Germanic_languages', 0.6159801483154297),\n",
       " ('sociolinguistics', 0.6143744587898254),\n",
       " ('linguist', 0.604064404964447),\n",
       " ('Slavic_languages', 0.5951172113418579),\n",
       " ('sociology_anthropology', 0.5915637016296387)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"linguistics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한 단어와 유사한 벡터값을 갖는 다른 단어를 찾는 것 뿐만 아니라, 여러가지 조건을 부여하여 검색할 수도 있습니다. 아래의 코드는 `woman`, `king`과는 유사하지만 `man`과는 거리가 먼 상위 10개 단어를 반환합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7118192911148071),\n",
       " ('monarch', 0.6189674139022827),\n",
       " ('princess', 0.5902431011199951),\n",
       " ('crown_prince', 0.5499460697174072),\n",
       " ('prince', 0.5377321243286133),\n",
       " ('kings', 0.5236844420433044),\n",
       " ('Queen_Consort', 0.5235945582389832),\n",
       " ('queens', 0.518113374710083),\n",
       " ('sultan', 0.5098593235015869),\n",
       " ('monarchy', 0.5087411999702454)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['woman', 'king'], negative=['man'], topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "개별 단어 사이의 유사도도 계산할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between girl and woman:  0.7494640637680033\n",
      "Similarity between girl and man:  0.5921714079716728\n",
      "Similarity between king and woman:  0.1284797355703921\n",
      "Similarity between king and man:  0.22942670457565928\n"
     ]
    }
   ],
   "source": [
    "print(\"Similarity between girl and woman: \", model.similarity(\"girl\", \"woman\"))\n",
    "print(\"Similarity between girl and man: \", model.similarity(\"girl\", \"man\"))\n",
    "print(\"Similarity between king and woman: \", model.similarity(\"king\", \"woman\"))\n",
    "print(\"Similarity between king and man: \", model.similarity(\"king\", \"man\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "값을 비교해보면 `girl-woman`의 유사도가 `girl-man`의 유사도보다 높은 값을 보이는 것을 알 수 있습니다. 또한 `king-woman`의 유사도가 `king-man`의 유사도보다 낮다는 것도 볼 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`gensim` 패키지를 사용하면 벡터값을 이용하여 그 벡터와 유사한 단어를 알아볼 수도 있습니다. `king`의 벡터에서 `man`의 벡터를 뺀 값과 유사한 단어들이 무엇이 있는지 보겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('king', 0.7256942987442017),\n",
       " ('kings', 0.5061088800430298),\n",
       " ('queen', 0.4603358507156372),\n",
       " ('monarch', 0.43495792150497437),\n",
       " ('Pansy_Ho_Chiu', 0.4200039505958557),\n",
       " ('princes', 0.411652147769928),\n",
       " ('kingdom', 0.4114915728569031),\n",
       " ('Savory_aromas_wafted', 0.40622571110725403),\n",
       " ('crown_prince', 0.4018521308898926),\n",
       " ('sultan', 0.39996951818466187)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_king_man = np.subtract(model[\"king\"], model[\"man\"])\n",
    "model.similar_by_vector(diff_king_man, topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "이처럼 `word2vec`을 이용하면 단어간의 의미적 유사도를 확인할 수 있습니다. 앞으로는 이를 이용하여 텍스트 분류 및 감성 분석을 진행해보도록 하겠습니다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

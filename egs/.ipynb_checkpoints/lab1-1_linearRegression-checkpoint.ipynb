{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "**Note:** 이 `notebook`을 실행하기 이전에, 전반적인 `선형 회귀(linear regression)`에 관한 내용과 `weight`, `bias`에 관한 내용을 설명하고 진행하여야 합니다. 또한 `선형 회귀(linear regression)`에서 `정확도 (accuracy)` 대신에 사용하는 `Mean Squared Error (MSE)` 값에 대한 설명도 미리 진행되어야 합니다. \n",
    "\n",
    "`선형 회귀(linear regression)`에 관하여 알아보겠습니다. 이번에 사용할 데이터는 `CMU Pronunciation Dictionary`이며, 분석할 내용은 단어의 길이를 이용하여 음절의 갯수를 예측하는 것입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "우리는 `**massaged_cmudict.txt**` 파일을 데이터로 이용하겠습니다. 이 파일의 첫 번째 열에는 실제 단어가, 두 번째 열에는 단어의 길이, 그리고 마지막 열에는 음절의 갯수가 들어있습니다. 우리는 두 번째와 세 번째 열을 사용하여 분석을 진행하겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\t1\t1\n",
      "A\t1\t1\n",
      "A'S\t2\t1\n",
      "A.\t1\t1\n",
      "A.'S\t2\t1\n",
      "A.S\t2\t1\n",
      "A42128\t6\t6\n",
      "AA\t2\t2\n",
      "AAA\t3\t3\n",
      "AABERG\t6\t2\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "head data/massaged_cmudict.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load modules\n",
    "\n",
    "`python`에서는 사용하고자 하는 모듈을 `import` 기능을 사용하여 불러와야 합니다. \n",
    "\n",
    "**`numpy`**는 행렬 계산을 쉽게 할 수 있도록 도와주는 모듈입니다. 2일차 `notebook`에서 `numpy`를 활용하여서 실제 `신경망 (Neural Networks)`를 구성하는 과정을 다루게 됩니다. 대부분의 `딥러닝` 툴은 `numpy` 타입의 변수를 입력값으로 요구합니다. 그렇기 때문에 `선형 회귀 (linear regression)` 뿐만 아니라 `딥러닝`을 `python`에서 다루기 위해서는 `numpy`에 익숙해지는 것이 중요합니다. \n",
    "\n",
    "**`keras`**는 `딥러닝` 툴 중의 하나이며, `딥러닝` 모델의 구조를 만들 때 사용합니다. 실제로 그 구조를 이용하여 `training`, 혹은 `test` 하는 과정은 **`tensorflow`**를 이용하여서 하게 됩니다. 바로 `tensorflow`를 사용하지 않고 `keras`를 사용하는 이유는, 실제 `딥러닝` 모델의 구조를 이해하는 것이 `keras`에서 조금 더 쉽기 때문입니다. `tensorflow`에서는 각 레이어의 입력/출력값의 구조 등에 대한 정보도 늘 계산하여야하지만, `keras`에서는 기본적인 것들은 자동적으로 계산해줍니다. 또한 `tensorflow`에서는 `weight`와 `bias`에 관한 변수들을 미리 설정해야하는 것에 비해, `keras`에서는 자동으로 변수들이 설정됩니다. \n",
    "\n",
    "아래 명령어를 사용하여서 필요한 모듈들을 `python`에서 불러오도록 하겠습니다. \n",
    "\n",
    "**Note:** `numpy`에서 변수명 변화가 있었기 때문에, 관련된 경고메시지가 뜰 수 있습니다. 무시하셔도 괜찮습니다. 경고 메시지의 내용은 `numpy`에서 `numpy` 행렬의 타입을 설정할 때 명령어의 변화가 있을 예정이라는 것입니다. \n",
    "\n",
    "**Note:** `Using TensorFlow backend` 라는 메시지는 `tensorflow`를 사용하여서 실제 `training`과 `test`를 진행한다는 것입니다. `tensorflow` 이외에도 `Theano`를 사용하여서 `keras`를 사용할 수도 있습니다. 그 경우, 입력값의 차원 수(`dimension`)를 입력하는 방법이 `tensorflow`와 다를 수 있습니다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras import optimizers\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "아래 명령어를 사용하여서 **massaged_cmudict.txt** 파일을 불러와서 그 값을 *f*라는 변수에 저장하겠습니다. 이 과정에서는 파일의 내용을 실제로 불러오지는 않습니다. 그 다음 명령어인 `readlines()` 명령어를 사용하여 파일의 각 줄(line)을 리스트의 형태로 `data`라는 변수에 저장하겠습니다. `readlines()` 기능은 파일을 불러온 *f* 변수의 내용을 읽어온 이후, `\\n`을 이용하여 구분된 각각의 줄을 `<list>`의 형태로 해당 변수에 저장하는 것입니다. 파일의 내용을 `data` 변수에 저장한 이후, `f`를 닫은 이후, `data` 변수에 내용이 제대로 저장되었는지 확인하겠습니다. \n",
    "\n",
    "**Note:** `python`에서는 기능을 적용할 때, `변수 = [기능이 적용될 변수].[기능]()`의 형태로 명령어를 사용합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\t1\t1\n",
      "\n",
      "A\t1\t1\n",
      "\n",
      "A'S\t2\t1\n",
      "\n",
      "A.\t1\t1\n",
      "\n",
      "A.'S\t2\t1\n",
      "\n",
      "A.S\t2\t1\n",
      "\n",
      "A42128\t6\t6\n",
      "\n",
      "AA\t2\t2\n",
      "\n",
      "AAA\t3\t3\n",
      "\n",
      "AABERG\t6\t2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/massaged_cmudict,txt\", \"r\") as f:\n",
    "    data = f.readlines()\n",
    "    f.close()\n",
    "    \n",
    "for i in range(0, 10):\n",
    "    print(data[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과를 살펴보면 파일의 각 줄을 제대로 읽어와서 변수에 저장하였음을 알 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data\n",
    "\n",
    "이제 우리는 읽어온 데이터에서 `predictor`와 `result`를 가지고 와서 서로 다른 `<list>`에 저장해두어야 합니다. 아래 스크립트에서 `X`는 predictor, 즉 **실제 단어의 길이**를 저장할 장소이고, `y`는 result, 즉 **실제 음절의 길이**를 저장할 장소입니다. \n",
    "\n",
    "**split()** 기능은 주어진 변수를 `delimiter`를 사용하여 나누는 기능입니다. default delimiter는 **공백**입니다. 우리가 사용한 데이터에는 `tsv (tab-separated version)`이기 때문에, **split()** 기능에 delimiter를 명시하여 **split(\"\\t\")** 를 사용하였습니다. **split()** 명령어는 `str` 타입을 반환하기 때문에, 숫자값들을 **int()** 명령어를 사용하여 실제 숫자로 바꿔주겠습니다. \n",
    "\n",
    "마지막으로 **X**와 **y** 데이터의 수가 같은지 확인하겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133779\n",
      "133779\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "for line in data:\n",
    "    (word, word_len, syll_len) = line.split(\"\\t\")\n",
    "    X.append(int(word_len))\n",
    "    y.append(int(syll_len))\n",
    "    \n",
    "print(len(X))\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training, validation, test data\n",
    "\n",
    "총 데이터의 갯수는 133,779개입니다. 우리는 주어진 데이터를 **세 가지** 데이터셋으로 분리할 것입니다. 먼저 `training` 데이터셋은 실제 모델을 구축하기 위해서 사용할 데이터입니다. 두 번째 `validation` 데이터셋은 모델을 구축하는 과정에서 `오버피팅 (over-fitting)` 여부를 확인하기 위해서 `training` 과정에서 결과값을 확인하기 위해 사용하는 데이터셋입니다. 마지막으로 `test` 데이터셋은 실제 모델의 **`performance`** 를 확인하기 위해서 사용할 데이터셋입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "30000\n",
      "3779\n"
     ]
    }
   ],
   "source": [
    "X_train = X[0:100000]\n",
    "y_train = y[0:100000]\n",
    "\n",
    "print(len(X_train))\n",
    "\n",
    "X_val = X[100000:130000]\n",
    "y_val = y[100000:130000]\n",
    "\n",
    "print(len(X_val))\n",
    "\n",
    "X_test = X[130000:]\n",
    "y_test = y[130000:]\n",
    "\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최종적으로 100,000개의 `training` 데이터, 30,000개의 `validation` 데이터, 그리고 3,779개의 `test` 데이터로 나누었습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a model\n",
    "\n",
    "`keras`에서 제공하는 **Sequential()** 기능을 이용하여 모델을 구성해보도록 하겠습니다. **Sequential()** 모델을 쉽게 이야기하면 순서대로 `layer`를 쌓아가면서 모델을 만드는 것입니다. 초기에 **Sequential()** 명령어를 이용하여서 우리가 구축할 모델의 종류를 결정한 다음, **add()** 기능을 사용하여서 우리가 원하는 `layer`를 쌓아나가면 됩니다. **Dense()** 레이어는 가장 쉽게 사용할 수 있는 `layer`의 형태입니다. **Dense(1, input_dim=1)** 이 나타내는 바든, 하나의 입력값을 받아서 하나의 출력값을 반환한다는 것입니다. \n",
    "\n",
    "**Mean Square Error (MSE)** 값을 이용하여서 모델을 학습시키도록 하겠습니다. 모델의 목표는 **MSE** 값을 최소화하는 것입니다. \n",
    "\n",
    "최종적으로는 **fit()** 명령어를 사용하여서 모델을 학습시키게 됩니다. \n",
    "\n",
    "**Note:** Tensorboard 변수를 설정하고 **`callbacks=[tensorboard]`** 를 **fit()** 기능에 논항으로 추가하면 나중에 `tensorflow`에서 제공하는 `tensorboard` 기능을 사용하여 학습 과정을 살펴볼 수 있습니다. `tensorboard` 사용 방법은 나중에 설명하도록 하겠습니다. \n",
    "\n",
    "**fit()** 명령어에 사용된 논항들의 역할은 다음과 같습니다. \n",
    "\n",
    " - **batch_size:** how many data we will look at once\n",
    "\n",
    " - **epochs:** how many times we will iterate the whole data\n",
    "\n",
    " - **verbose:** how to display the training process\n",
    "\n",
    " - **validation_data:** which will be used as validation data\n",
    "\n",
    " - **shuffle:** whether we will shuffle the training data or not\n",
    "\n",
    " - **callbacks:** how to keep track of the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100000 samples, validate on 30000 samples\n",
      "Epoch 1/10\n",
      "100000/100000 [==============================] - 1s 6us/step - loss: 0.7305 - mean_squared_error: 0.7305 - val_loss: 0.4570 - val_mean_squared_error: 0.4570\n",
      "Epoch 2/10\n",
      "100000/100000 [==============================] - 1s 6us/step - loss: 0.4075 - mean_squared_error: 0.4075 - val_loss: 0.4511 - val_mean_squared_error: 0.4511\n",
      "Epoch 3/10\n",
      "100000/100000 [==============================] - 1s 6us/step - loss: 0.4071 - mean_squared_error: 0.4071 - val_loss: 0.4532 - val_mean_squared_error: 0.4532\n",
      "Epoch 4/10\n",
      "100000/100000 [==============================] - 1s 6us/step - loss: 0.4066 - mean_squared_error: 0.4066 - val_loss: 0.4489 - val_mean_squared_error: 0.4489\n",
      "Epoch 5/10\n",
      "100000/100000 [==============================] - 1s 6us/step - loss: 0.4062 - mean_squared_error: 0.4062 - val_loss: 0.4513 - val_mean_squared_error: 0.4513\n",
      "Epoch 6/10\n",
      "100000/100000 [==============================] - 1s 6us/step - loss: 0.4059 - mean_squared_error: 0.4059 - val_loss: 0.4530 - val_mean_squared_error: 0.4530\n",
      "Epoch 7/10\n",
      "100000/100000 [==============================] - 1s 6us/step - loss: 0.4056 - mean_squared_error: 0.4056 - val_loss: 0.4561 - val_mean_squared_error: 0.4561\n",
      "Epoch 8/10\n",
      "100000/100000 [==============================] - 1s 6us/step - loss: 0.4054 - mean_squared_error: 0.4054 - val_loss: 0.4561 - val_mean_squared_error: 0.4561\n",
      "Epoch 9/10\n",
      "100000/100000 [==============================] - 1s 6us/step - loss: 0.4053 - mean_squared_error: 0.4053 - val_loss: 0.4590 - val_mean_squared_error: 0.4590\n",
      "Epoch 10/10\n",
      "100000/100000 [==============================] - 1s 7us/step - loss: 0.4052 - mean_squared_error: 0.4052 - val_loss: 0.4596 - val_mean_squared_error: 0.4596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8c5e0468d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=1))\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='./logs', histogram_freq = 0, \n",
    "                         write_graph=True, write_images=False)\n",
    "\n",
    "model.fit(X_train, y_train, batch_size = 256, epochs = 10, verbose = 1, validation_data=(X_val, y_val), \n",
    "          shuffle = True, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch이 증가함에 따라서 `MSE (loss)`도 줄어드는 것을 볼 수 있습니다. 그리고 `validation` 데이터의 `MSE (loss)` 값은 커졌다 작아지는 과정을 반복합니다. 이 것은 우리가 구축한 모델이 `weight`와 `bias` 값을 조정하는 과정입니다. 최적의 `weight`와 `bias` 값을 찾아내기 위해서 값을 변경하는 과정에서 `MSE (loss)`가 커지기도, 작아지기도 하는 것입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "`test` 데이터에 있는 **실제 단어 길이**를 이용하여서 모델이 예측한 **예측된 음절 길이**가 **실제 음절 길이**와 얼마나 다른지 비교하여서 모델의 성능을 평가할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3779/3779 [==============================] - 0s 26us/step\n",
      "[0.37081340698613535, 0.37081340698613535]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`test` 데이터에 대한 `MSE` 값은 0.37로, `training`이나 `validation` 데이터에서 보여준 것 보다 높은 성능을 보여줍니다. 이는 `오버피팅 (over-fitting)`은 일어나지 않았다는 것을 의미합니다. \n",
    "\n",
    "`Evaluation`의 다른 방법으로, 실제 단어의 예측된 음절 갯수와 실제 음절 갯수를 출력해보겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8abfe64e4df1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "for i in range(0, len(predictions)):\n",
    "    print(X_test[i], \"\\t\", predictions[i][0], \"\\t\", y_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief explanation about linear regression\n",
    "\n",
    "`선형 회귀 (linear regression)` 모델은 **`ax+b`** 의 구조를 갖습니다. 우리가 예전에 수학 시간에 배운 것 처럼, **a**는 직선의 *기울기(slope)* 를 의미하고, **b**는 *y 절편 (intercept)* 를 의미합니다. 우리는 **get_weights()** 명령어를 사용하여 **a**와 **b** 값을 확인할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight:\t [[0.37810433]]\n",
      "Bias:\t [-0.3286158]\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    weight = layer.get_weights()[0]\n",
    "    bias = layer.get_weights()[1]\n",
    "    print(\"Weight:\\t\", weight)\n",
    "    print(\"Bias:\\t\", bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최종적으로 우리는 `선형 회귀 (linear regression)` 모델이 `**0.378 x - 0.3286**` 구조를 이용하여서 음절 갯수를 예측한다는 것을 알 수 있습니다. 즉, **x** 자리에 **실제 단어의 길이**를 넣은 결과값이 **예측된 음절 길이**인 것입니다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

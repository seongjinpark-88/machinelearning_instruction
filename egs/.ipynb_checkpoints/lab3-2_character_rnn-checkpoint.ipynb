{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks (RNNs)\n",
    "\n",
    "**Note:** 이 `notebook`을 실행하기 이전에 다음과 같은 내용을 설명하고 진행하도록 하겠습니다. \n",
    " 1. One-hot encoding 설명\n",
    " 2. Recurrent Neural Networks의 구조\n",
    " \n",
    " 3. 여러가지 다른 형태의 RNNs 설명\n",
    "   - 다대다 (각각의 cell이 입력과 출력을 하는 경우)\n",
    "   - 다대다 (seq2seq: machine translation)\n",
    "   - 일대다 (img2seq)\n",
    "   - 다대일 (text classification, sentiment analysis)\n",
    " 4. Vanilla RNN과 LSTM, GRU cell의 차이점\n",
    "  \n",
    "**Note:** 이 `notebook`의 설명과 코드는 **Deep Learning with Keras** 책을 참고하였습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번에는 `순환 신경망 (Recurrent Neural Networks; RNNs)`을 이용하여서 문자열을 생성하는 모델을 확인해보도록 하겠습니다. 이 스크립트에서 하는 작업은 이전 단어가 주어졌을 때 현재 단어가 나올 확률을 예측하는 것입니다. 지금은 단어가 아닌 각각의 글자 단위로 언어 모델을 구축해보겠습니다. \n",
    "\n",
    "사용할 데이터는 `이상한 나라의 엘리스` 문장입니다. 주어진 텍스트에서 10개의 글자를 입력으로 받아서 다음 글자를 예측하는 모델을 만드는 것을 목적으로 합니다. 단어 단위가 아닌 글자 단위로 학습을 하는 이유는 단어의 갯수보다 글자의 갯수가 적으므로 학습을 더 빠르게 진행할 수 있기 때문입니다. 워크샵에서 단어 단위의 모델을 형성하는 것에는 시간이 오래 걸릴 수 있으므로, 글자 단위의 모델을 만들어 보겠습니다. \n",
    "\n",
    "모델이 잘 학습이 된다면 생성된 결과도 좋을 것이고, 모델이 잘 학습이 되지 않을 경우 이상한 문장들을 생성해낼 것입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the data\n",
    "\n",
    "데이터를 확인해보겠습니다. 이 데이터는 Project Gutenberg에서 제공하는 `Aclice in the Wonderland`의 일부를 가지고 온 것입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice was beginning to get very tired of sitting by her sister on the\r\n",
      "bank, and of having nothing to do: once or twice she had peeped into the\r\n",
      "book her sister was reading, but it had no pictures or conversations in\r\n",
      "it, ���and what is the use of a book,��� thought Alice ���without pictures or\r\n",
      "conversations?���\r\n",
      "\r\n",
      "So she was considering in her own mind (as well as she could, for the\r\n",
      "hot day made her feel very sleepy and stupid), whether the pleasure\r\n",
      "of making a daisy-chain would be worth the trouble of getting up and\r\n",
      "picking the daisies, when suddenly a White Rabbit with pink eyes ran\r\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "head ./data/11-0.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules\n",
    "\n",
    "RNN 모델 구축에 필요한 모듈을 불러오겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Activation\n",
    "from keras.layers.recurrent import SimpleRNN\n",
    "from keras.models import Sequential\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "이전에 데이터를 확인해 보면 인식되지 않는 기호들이 있고 줄바꿈이 제대로 되어있지 않으므로 전처리가 필요한 데이터임을 알 수 있습니다. 다음과 같이 데이터 전처리를 실행하도록 하겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, ‘and what is the use of a book,’ thought alice ‘without pictures or conversations?’ so she was considering in her own mind (as well as she could, for the hot day made her feel very sleepy and stupid), whether the pleasure of making a daisy-chain would be worth the trouble of getting up and picking the daisies, when suddenly a white rabbit with pink eyes ran close by her. there was nothing so very remarkable in that; nor did alice think it so very much out of the way to hear the rabbit say to itself, ‘oh dear! oh dear! i shall be late!’ (when she thought it over afterwards, it occurred to her that she ought to have wondered at this, but at the time it all seemed quite natural); but when the rabbit actually took a watch out of its waistcoat-pocket, and looked at it, and then hurried on, alice started to her feet, for it flashed across her mind that she had never before seen a rabbit with either a waistcoat-pocket, or a watch to take out of it, and burning with curiosity, she ran across the field after it, and fortunately was just in time to see it pop down a large rabbit-hole under the hedge. in another moment down went alice after it, never once considering how in the world she was to get out again. the rabbit-hole went straight on like a tunnel for some way, and then dipped suddenly down, so suddenly that alice had not a moment to think about stopping herself before she found herself falling down a very deep well. either the well was very deep, or she fell very slowly, for she had plenty of time as she went down to look about her and to wonder what was going to happen next. first, she tried to look down and make out what she was coming to, but it was too dark to see anything; then she looked at the sides of the well, and noticed that they were filled with cupboards and book-shelves; here and there she saw maps and pictures hung upon pegs. she took down a jar from one of the shelves as she passed; it was labelled ‘orange marmalade’, but to her great disappointment it was empty: she did not like to drop the jar for fear of killing somebody, so managed to put it into one of the cupboards as she fell past it. ‘well!’ thought alice to herself, ‘after such a fall as this, i shall think nothing of tumbling down stairs! how brave they’ll all think me at home! why, i wouldn’t say anything about it, even if i fell off the top of the house!’ (which was very likely true.) down, down, down. would the fall never come to an end! ‘i wonder how many miles i’ve fallen by this time?’ she said aloud. ‘i must be getting somewhere near the centre of the earth. let me see: that would be four thousand miles down, i think--’ (for, you see, alice had learnt several things of this sort in her lessons in the schoolroom, and though this was not a very good opportunity for showing off her knowledge, as there was no one to listen to her, still it was good practice to say it over) ‘--yes, that’s about the right distance--but then i wonder what latitude or longitude i’ve got to?’ (alice had no idea what latitude was, or longitude either, but thought they were nice grand words to say.) presently she began again. ‘i wonder if i shall fall right through the earth! how funny it’ll seem to come out among the people that walk with their heads downward! the antipathies, i think--’ (she was rather glad there was no one listening, this time, as it didn’t sound at all the right word) ‘--but i shall have to ask them what the name of the country is, you know. please, ma’am, is this new zealand or australia?’ (and she tried to curtsey as she spoke--fancy curtseying as you’re falling through the air! do you think you could manage it?) ‘and what an ignorant little girl she’ll think me for asking! no, it’ll never do to ask: perhaps i shall see it written up somewhere.’ down, down, down. there was nothing else to do, so alice soon began talking again. ‘dinah’ll miss me very much to-night, i should think!’ (dinah was the cat.) ‘i hope they’ll remember her saucer of milk at tea-time. dinah my dear! i wish you were down here with me! there are no mice in the air, i’m afraid, but you might catch a bat, and that’s very like a mouse, you know. but do cats eat bats, i wonder?’ and here alice began to get rather sleepy, and went on saying to herself, in a dreamy sort of way, ‘do cats eat bats? do cats eat bats?’ and sometimes, ‘do bats eat cats?’ for, you see, as she couldn’t answer either question, it didn’t much matter which way she put it. she felt that she was dozing off, and had just begun to dream that she was walking hand in hand with dinah, and saying to her very earnestly, ‘now, dinah, tell me the truth: did you ever eat a bat?’ when suddenly, thump! thump! down she came upon a heap of sticks and dry leaves, and the fall was over. alice was not a bit hurt, and she jumped up on to her feet in a moment: she looked up, but it was all dark overhead; before her was another long passage, and the white rabbit was still in sight, hurrying down it. there was not a moment to be lost: away went alice like the wind, and was just in time to hear it say, as it turned a corner, ‘oh my ears and whiskers, how late it’s getting!’ she was close behind it when she turned the corner, but the rabbit was no longer to be seen: she found herself in a long, low hall, which was lit up by a row of lamps hanging from the roof. there were doors all round the hall, but they were all locked; and when alice had been all the way down one side and up the other, trying every door, she walked sadly down the middle, wondering how she was ever to get out again. suddenly she came upon a little three-legged table, all made of solid glass; there was nothing on it except a tiny golden key, and alice’s first thought was that it might belong to one of the doors of the hall; but, alas! either the locks were too large, or the key was too small, but at any rate it would not open any of them. however, on the second time round, she came upon a low curtain she had not noticed before, and behind it was a little door about fifteen inches high: she tried the little golden key in the lock, and to her great delight it fitted! alice opened the door and found that it led into a small passage, not much larger than a rat-hole: she knelt down and looked along the passage into the loveliest garden you ever saw. how she longed to get out of that dark hall, and wander about among those beds of bright flowers and those cool fountains, but she could not even get her head through the doorway; ‘and even if my head would go through,’ thought poor alice, ‘it would be of very little use without my shoulders. oh, how i wish i could shut up like a telescope! i think i could, if i only knew how to begin.’ for, you see, so many out-of-the-way things had happened lately, that alice had begun to think that very few things indeed were really impossible. there seemed to be no use in waiting by the little door, so she went back to the table, half hoping she might find another key on it, or at any rate a book of rules for shutting people up like telescopes: this time she found a little bottle on it, [‘which certainly was not here before,’ said alice,) and round the neck of the bottle was a paper label, with the words ‘drink me’ beautifully printed on it in large letters. it was all very well to say ‘drink me,’ but the wise little alice was not going to do that in a hurry. ‘no, i’ll look first,’ she said, ‘and see whether it’s marked “poison” or not’; for she had read several nice little histories about children who had got burnt, and eaten up by wild beasts and other unpleasant things, all because they would not remember the simple rules their friends had taught them: such as, that a red-hot poker will burn you if you hold it too long; and that if you cut your finger very deeply with a knife, it usually bleeds; and she had never forgotten that, if you drink much from a bottle marked ‘poison,’ it is almost certain to disagree with you, sooner or later. however, this bottle was not marked ‘poison,’ so alice ventured to taste it, and finding it very nice, (it had, in fact, a sort of mixed flavour of cherry-tart, custard, pine-apple, roast turkey, toffee, and hot buttered toast,) she very soon finished it off. ‘what a curious feeling!’ said alice; ‘i must be shutting up like a telescope.’ and so it was indeed: she was now only ten inches high, and her face brightened up at the thought that she was now the right size for going through the little door into that lovely garden. first, however, she waited for a few minutes to see if she was going to shrink any further: she felt a little nervous about this; ‘for it might end, you know,’ said alice to herself, ‘in my going out altogether, like a candle. i wonder what i should be like then?’ and she tried to fancy what the flame of a candle is like after the candle is blown out, for she could not remember ever having seen such a thing. after a while, finding that nothing more happened, she decided on going into the garden at once; but, alas for poor alice! when she got to the door, she found she had forgotten the little golden key, and when she went back to the table for it, she found she could not possibly reach it: she could see it quite plainly through the glass, and she tried her best to climb up one of the legs of the table, but it was too slippery; and when she had tired herself out with trying, the poor little thing sat down and cried. ‘come, there’s no use in crying like that!’ said alice to herself, rather sharply; ‘i advise you to leave off this minute!’ she generally gave herself very good advice, (though she very seldom followed it), and sometimes she scolded herself so severely as to bring tears into her eyes; and once she remembered trying to box her own ears for having cheated herself in a game of croquet she was playing against herself, for this curious child was very fond of pretending to be two people. ‘but it’s no use now,’ thought poor alice, ‘to pretend to be two people! why, there’s hardly enough of me left to make one respectable person!’ soon her eye fell on a little glass box that was lying under the table: she opened it, and found in it a very small cake, on which the words ‘eat me’ were beautifully marked in currants. ‘well, i’ll eat it,’ said alice, ‘and if it makes me grow larger, i can reach the key; and if it makes me grow smaller, i can creep under the door; so either way i’ll get into the garden, and i don’t care which happens!’ she ate a little bit, and said anxiously to herself, ‘which way? which way?’, holding her hand on the top of her head to feel which way it was growing, and she was quite surprised to find that she remained the same size: to be sure, this generally happens when one eats cake, but alice had got so much into the way of expecting nothing but out-of-the-way things to happen, that it seemed quite dull and stupid for life to go on in the common way. so she set to work, and very soon finished off the cake.\n"
     ]
    }
   ],
   "source": [
    "## Data massage\n",
    "with open(\"./data/11-0.txt\", \"rb\") as f:\n",
    "    lines = []\n",
    "    for line in f:\n",
    "        line = line.strip().lower()\n",
    "        line = line.decode(\"utf-8\", \"ignore\")\n",
    "        if len(line) == 0:\n",
    "            continue\n",
    "        lines.append(line)\n",
    "    f.close()\n",
    "text = \" \".join(lines)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과를 보면 이제 모든 내용이 하나의 긴 글로 연결되어 있음을 알 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Char2Idx\n",
    "\n",
    "문자 단위의 `RNN` 모델을 만들기 위해서는 사용된 문자들과 그 문자에 해당하는 인덱스를 연결시켜줄 필요가 있습니다. \n",
    "\n",
    "주어진 데이터는 총 41개의 문자를 사용하며, 아래 코드를 이용하여 `Character-to-Index` 작업을 하겠습니다. \n",
    "\n",
    "**Note:** `enumerate` 함수의 기능을 알면 유용합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "41\n",
      "['y', ',', 'p', '?', ' ', '.', 'd', 'c', 'k', '‘']\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "chars = set([c for c in text])\n",
    "print(len(chars))\n",
    "\n",
    "num_chars = len(chars)\n",
    "\n",
    "char2idx = dict((c, i) for i, c in enumerate(chars))\n",
    "\n",
    "idx2char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "print(len(list(char2idx.keys())))\n",
    "print(list(char2idx.keys())[:10])\n",
    "print(list(idx2char.keys())[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input/output text\n",
    "\n",
    "다음으로 입력과 출력에 해당하는 텍스트를 추출하여야합니다. \n",
    "\n",
    "이번 `notebook`에서 진행할 과정은 10개의 문자가 주어졌을 때, 다음에 나타날 하나의 문자를 예측하는 것입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice was  \t=>\t b\n",
      "lice was b \t=>\t e\n",
      "ice was be \t=>\t g\n",
      "ce was beg \t=>\t i\n",
      "e was begi \t=>\t n\n",
      " was begin \t=>\t n\n",
      "was beginn \t=>\t i\n",
      "as beginni \t=>\t n\n",
      "s beginnin \t=>\t g\n",
      " beginning \t=>\t  \n"
     ]
    }
   ],
   "source": [
    "seq_len = 10 # Length of input text\n",
    "step = 1 # interval between characters\n",
    "\n",
    "input_chars = []\n",
    "label_chars = []\n",
    "\n",
    "for i in range(0, len(text) - seq_len, step):\n",
    "    input_chars.append(text[i:i + seq_len])\n",
    "    label_chars.append(text[i + seq_len])\n",
    "    \n",
    "for j in range(0, 10):\n",
    "    print(input_chars[j], \"\\t=>\\t\", label_chars[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과를 살펴보면 `input_chars` 리스트에는 10개의 글자가 주어지고, `label_chars`에는 그 다음에 나타날 글자 하나가 들어있는 것을 볼 수 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text to Vectors\n",
    "\n",
    "다음으로는 `input_chars`와 `label_chars`에 들어있는 글자들을 벡터로 변환하여야 합니다. `RNN` 모델에 필요한 `cell`의 갯수는 `seq_len (input의 길이)`와 동일하며, 어휘의 크기는 `num_char`에 의해서 결정됩니다. 그리고 각각의 글자는 `num_char` 크기의 `one-hot encoding`의 형태로 변환되니다. \n",
    "\n",
    "결국 `input_chars`는 `input_chars의 길이 x seq_len x num_chars`의 형태를 가진 행렬로 변환되고, `label_chars`는 `input_chars의 길이 x num_chars`의 형태의 행렬로 변환됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create numpy arrays with zeros\n",
    "X_data = np.zeros((len(input_chars), seq_len, num_chars), dtype=np.bool)\n",
    "y_data = np.zeros((len(input_chars), num_chars), dtype=np.bool)\n",
    "\n",
    "## Replace zero to one for one-hot encoding\n",
    "for i, input_char in enumerate(input_chars):\n",
    "    for j, ch in enumerate(input_char):\n",
    "        X_data[i, j, char2idx[ch]] = 1\n",
    "    y_data[i, char2idx[label_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a model\n",
    "\n",
    "이제 모델을 만들어보도록 하겠습니다. `RNN`의 출력 공간은 **128**로 설정하였습니다. 많은 논문/실험에서 출력 공간을 128, 혹은 128의 배수로 설정하는 것을 볼 수 있습니다. 일반적으로 출력 공간의 크기는 input이나 output의 길이보다는 충분히 길어야합니다. 출력 공간이 너무 작게 설정되면 모델의 수용력이 부족해져서 제대로 학습을 하지 못하는 경우가 있으며, 출력 공간이 너무 클 경우에는 학습을 위해 충분히 많은 양의 데이터를 필요로 합니다. \n",
    "\n",
    "`keras`에서 `RNN cell`에는 `return_sequences` 라는 논항이 있습니다. 현재 우리는 문자열이 아니라 하나의 글자를 반환하기를 원하므로, `False`로 설정합니다. \n",
    "\n",
    "`RNN`에 입력될 데이터는 `seq_len x num_char`의 형태로 입력될 것입니다. \n",
    "\n",
    "`RNN` 모델의 논항 중, `unroll = True`는 `keras` 실행에 사용되는 `tensorflow`의 성능을 향상시키므로 `true`로 설정하여씃ㅂ니다. \n",
    "\n",
    "`RNN` 모델의 마지막 단은 `Fully-connected layer`에 연결됩니다. `Fully-connected layer`의 **output**은 `num_char` 만큼의 노드가 잇으며, 각각의 노드는 해당 글자로 나타날 점수를 출력합니다. 다음으로 `softmax` 활성화 함수를 이용하여서 각각의 점수를 확률로 정규화하며, 확률이 가장 높은 문자가 예측값으로 선택됩니다. 예측값과 실제값의 차이는 `categorical_corrsentropy` 함수를 이용하여 계산되며, `Adam` optimizer를 사용하여 `weight` 및 `bias`를 최적화하였습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_6 (SimpleRNN)     (None, 128)               21760     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 41)                5289      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 41)                0         \n",
      "=================================================================\n",
      "Total params: 27,049\n",
      "Trainable params: 27,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## hyperparameters\n",
    "hidden_dim = 128\n",
    "batch_size = 128\n",
    "num_iterations = 50\n",
    "num_epochs = 5\n",
    "num_preds = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(hidden_dim, return_sequences=False,\n",
    "                   input_shape = (seq_len, num_chars),\n",
    "                   unroll = True))\n",
    "model.add(Dense(num_chars))\n",
    "model.add(Activation(\"softmax\"))\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "이제 만들어놓은 모델을 주어진 데이터를 이용하여 학습시켜보도록 하겠습니다. 이전에는 주어진 학습 데이터를 통해 모델을 학습시킨 이후, 학습된 모델이 주어진 테스트 데이터에 대해 얼마의 `accuracy (정확도)`를 보이는지, 혹은 실제 값과의 `오차 (loss)`가 얼마나 되는지를 통해 학습 및 평가를 진행하였습니다. \n",
    "\n",
    "이번에는 모델을 학습시킨 이후, 실제 문자열을 생성함으로써 얼마나 모델이 잘 학습되었는지 살펴보도록 하겠습니다. 테스트는 `input_chars`중 임의로 하나를 가져온 다음, 해당 문자열 다음에 나타날 하나의 글자를 모델을 통해 예측합니다. 그리고 나서 해당 문자열의 첫 글자를 삭제, 예측한 글자를 해당 문자열의 맨 뒤에 붙인 다음 다시 학습된 모델을 이용하여 예측을 합니다. 이 과정을 **100번** (num_pred) 진행한 이후, 생성된 문자열을 통해 모델이 얼마나 잘 학습되었는지 확인할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Iteration #: 0\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 122us/step - loss: 2.9477\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 86us/step - loss: 2.6543\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 83us/step - loss: 2.4786\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 82us/step - loss: 2.3449\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 85us/step - loss: 2.2501\n",
      "Generating from seed: the locks \n",
      "the locks and the the to the was ao she was ao she was ao she was ao she was ao she was ao she was ao she was \n",
      "==================================================\n",
      "Iteration #: 1\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 82us/step - loss: 2.1739\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 86us/step - loss: 2.1076\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 85us/step - loss: 2.0597\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 87us/step - loss: 2.0161\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 85us/step - loss: 1.9750\n",
      "Generating from seed: ! how funn\n",
      "! how funn the was no hing the was no hing the was no hing the was no hing the was no hing the was no hing the\n",
      "==================================================\n",
      "Iteration #: 2\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 94us/step - loss: 1.9384\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 94us/step - loss: 1.9012\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 88us/step - loss: 1.8645\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 87us/step - loss: 1.8306\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 84us/step - loss: 1.7994\n",
      "Generating from seed: g seen suc\n",
      "g seen suche pitt at ind it tor and to the the the the the the the the the the the the the the the the the the\n",
      "==================================================\n",
      "Iteration #: 3\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 87us/step - loss: 1.7674\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 86us/step - loss: 1.7333\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 84us/step - loss: 1.7048\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 86us/step - loss: 1.6707\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 87us/step - loss: 1.6437\n",
      "Generating from seed: e of the c\n",
      "e of the callle soo to the foup of the her lithe selleng the for the could the came and the was not ing the wa\n",
      "==================================================\n",
      "Iteration #: 4\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 85us/step - loss: 1.6079\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 90us/step - loss: 1.5784\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 85us/step - loss: 1.5435\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 88us/step - loss: 1.5113\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 85us/step - loss: 1.4818\n",
      "Generating from seed: y rate a b\n",
      "y rate a bitt of all toon the rould tor anden the to the ked was tow she tould the for she could the came toon\n",
      "==================================================\n",
      "Iteration #: 5\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 89us/step - loss: 1.4501\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 86us/step - loss: 1.4246\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 87us/step - loss: 1.3885\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 91us/step - loss: 1.3573\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 87us/step - loss: 1.3309\n",
      "Generating from seed: , and when\n",
      ", and when alice had be withe chis andithey ingh she loople to meke the was and inge she little gorden to her \n",
      "==================================================\n",
      "Iteration #: 6\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 88us/step - loss: 1.3019\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 86us/step - loss: 1.2728\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 88us/step - loss: 1.2518\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 90us/step - loss: 1.2116\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 86us/step - loss: 1.1907\n",
      "Generating from seed: ry deep we\n",
      "ry deep wers beat atall and poond it was ato taiked in which capine thing inte her if in was ealy, and hedend \n",
      "==================================================\n",
      "Iteration #: 7\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 87us/step - loss: 1.1629\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 89us/step - loss: 1.1367\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 88us/step - loss: 1.1117\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 88us/step - loss: 1.0892\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 91us/step - loss: 1.0609\n",
      "Generating from seed: table pers\n",
      "table persen! thas ander heree fon likel, aud she calling to be tho get of the way co lander heas and thatke f\n",
      "==================================================\n",
      "Iteration #: 8\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 92us/step - loss: 1.0398\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 88us/step - loss: 1.0150\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 86us/step - loss: 0.9869\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 92us/step - loss: 0.9646\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 91us/step - loss: 0.9421\n",
      "Generating from seed: hink that \n",
      "hink that she was now the rould the eas coust inther a d onkeratt bhe raydin thour the fowrs ank thetee foors \n",
      "==================================================\n",
      "Iteration #: 9\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 91us/step - loss: 0.9240\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 87us/step - loss: 0.9006\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 87us/step - loss: 0.8804\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 88us/step - loss: 0.8604\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 88us/step - loss: 0.8442\n",
      "Generating from seed: wever, on \n",
      "wever, on the ser oa dit and ald wall she was got in a and her mast inge it ing to her very lice very anon tum\n",
      "==================================================\n",
      "Iteration #: 10\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 93us/step - loss: 0.8215\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 90us/step - loss: 0.7987\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 87us/step - loss: 0.7828\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 89us/step - loss: 0.7610\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 91us/step - loss: 0.7482\n",
      "Generating from seed: n.’ for, y\n",
      "n.’ for, you see, all, the s math ankithin she west batint (ast elo them whet an to hed preall thereas!en ting\n",
      "==================================================\n",
      "Iteration #: 11\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 92us/step - loss: 0.7259\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 95us/step - loss: 0.7146\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 89us/step - loss: 0.6948\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 93us/step - loss: 0.6759\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 93us/step - loss: 0.6559\n",
      "Generating from seed:  not possi\n",
      " not possiblings hat ite sablif thi she was gline ut the lembll of oo, then west bet lonke pey upres, bre thow\n",
      "==================================================\n",
      "Iteration #: 12\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 95us/step - loss: 0.6518\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 89us/step - loss: 0.6310\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 89us/step - loss: 0.6207\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 87us/step - loss: 0.6056\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 91us/step - loss: 0.5919\n",
      "Generating from seed: s i shall \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s i shall sall thithan then wey in the loppided or here mace oreed wa chat a vinthe lask, und harse!’ sard hem\n",
      "==================================================\n",
      "Iteration #: 13\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 90us/step - loss: 0.5776\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 86us/step - loss: 0.5660\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 90us/step - loss: 0.5538\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 86us/step - loss: 0.5360\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 90us/step - loss: 0.5289\n",
      "Generating from seed:  very soon\n",
      " very soon finished off the coke ffen oup sayich vas mpton tureli gat withiug thouthorg to loke tipowhe at eel\n",
      "==================================================\n",
      "Iteration #: 14\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 90us/step - loss: 0.5170\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 88us/step - loss: 0.5022\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 84us/step - loss: 0.5006\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 85us/step - loss: 0.4823\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 90us/step - loss: 0.4723\n",
      "Generating from seed: ds and boo\n",
      "ds and book-sher thei’sd outher amy herrkes werdey why manise to mameno: she lackid )id way ileeshed of the sh\n",
      "==================================================\n",
      "Iteration #: 15\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 89us/step - loss: 0.4569\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 91us/step - loss: 0.4574\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 87us/step - loss: 0.4366\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 91us/step - loss: 0.4319\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 87us/step - loss: 0.4315\n",
      "Generating from seed:  before,’ \n",
      " before,’ sa d ankere the lakel, tire!) ‘-hadker thams! bhe wasdelped whit leanet ats apor of tof is, ala bug \n",
      "==================================================\n",
      "Iteration #: 16\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 92us/step - loss: 0.4210\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 87us/step - loss: 0.4009\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 91us/step - loss: 0.3957\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 89us/step - loss: 0.3999\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 91us/step - loss: 0.3941\n",
      "Generating from seed: ping herse\n",
      "ping herself be aile the severs for lo botllo tarke do thanke thathy weidd an the tonder, had sha rit we, all \n",
      "==================================================\n",
      "Iteration #: 17\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 87us/step - loss: 0.3789\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 88us/step - loss: 0.3736\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 87us/step - loss: 0.3602\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 87us/step - loss: 0.3641\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 89us/step - loss: 0.3465\n",
      "Generating from seed:  and was j\n",
      " and was just in time to hear it say, as it turned a corner, ‘oh my ears and whiskelicg ourdsiry, and downt un\n",
      "==================================================\n",
      "Iteration #: 18\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 87us/step - loss: 0.3409\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 88us/step - loss: 0.3362\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 94us/step - loss: 0.3341\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 91us/step - loss: 0.3321\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 88us/step - loss: 0.3228\n",
      "Generating from seed: r sharply;\n",
      "r sharply; ‘i advise you to leave off this minute!’ she generelly in too to me. ali g, tor anlit fithey yous, \n",
      "==================================================\n",
      "Iteration #: 19\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 86us/step - loss: 0.3180\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 88us/step - loss: 0.3152\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 88us/step - loss: 0.3124\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 88us/step - loss: 0.3047\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 88us/step - loss: 0.2940\n",
      "Generating from seed: : such as,\n",
      ": such as, that a rem-ho the dabra lackissey’s very loke bees acmisall; bouwns ais mor alice lop leatice sathe\n",
      "==================================================\n",
      "Iteration #: 20\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 88us/step - loss: 0.2985\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 89us/step - loss: 0.2934\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 88us/step - loss: 0.2896\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 89us/step - loss: 0.2926\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 89us/step - loss: 0.2933\n",
      "Generating from seed: es about c\n",
      "es about childing thith arkersenthall thalk o shemers hardingh whing then mever attereablit me at ass!?’ she s\n",
      "==================================================\n",
      "Iteration #: 21\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 87us/step - loss: 0.2793\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 91us/step - loss: 0.2784\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 96us/step - loss: 0.2732\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 95us/step - loss: 0.2706\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 91us/step - loss: 0.2547\n",
      "Generating from seed: s bottle w\n",
      "s bottle was a paper label, with the words ‘drink me’ beautifully printed on it in large lettipsty tee wasle. \n",
      "==================================================\n",
      "Iteration #: 22\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 89us/step - loss: 0.2563\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 94us/step - loss: 0.2566\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 97us/step - loss: 0.2516\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 93us/step - loss: 0.2500\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 90us/step - loss: 0.2521\n",
      "Generating from seed: st to clim\n",
      "st to climb up one of the doors of the hersolf alis sheme was, a f alice arind ot, but tow rand cower in thi h\n",
      "==================================================\n",
      "Iteration #: 23\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 93us/step - loss: 0.2549\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 90us/step - loss: 0.2478\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 95us/step - loss: 0.2503\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 93us/step - loss: 0.2489\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 100us/step - loss: 0.2498\n",
      "Generating from seed: ut again. \n",
      "ut again. the rabbit was stield ne, io sfolle to mevering, of but wallis wellnge steaver as iot lattirequmttig\n",
      "==================================================\n",
      "Iteration #: 24\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 96us/step - loss: 0.2376\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 86us/step - loss: 0.2389\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 89us/step - loss: 0.2304\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 84us/step - loss: 0.2289\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 98us/step - loss: 0.2300\n",
      "Generating from seed: t poor ali\n",
      "t poor alice, ‘to pretend to be the semise of dow it warca litt e tower, bo do want thished warheld brey mint \n",
      "==================================================\n",
      "Iteration #: 25\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 105us/step - loss: 0.2318\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 97us/step - loss: 0.2256\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 114us/step - loss: 0.2287\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 134us/step - loss: 0.2210\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11185/11185 [==============================] - 1s 96us/step - loss: 0.2267\n",
      "Generating from seed: s to say.)\n",
      "s to say.) presently she began and heas aes marker anour tho sabee, ho k-ou no flit me asen th mak way; bof we\n",
      "==================================================\n",
      "Iteration #: 26\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 91us/step - loss: 0.2138\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 86us/step - loss: 0.2189\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 87us/step - loss: 0.2230\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 86us/step - loss: 0.2215\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 88us/step - loss: 0.2147\n",
      "Generating from seed: one listen\n",
      "one listening, this time she found herself out with trying, the poor little thing sat down and cried. ‘come, t\n",
      "==================================================\n",
      "Iteration #: 27\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 86us/step - loss: 0.2131\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 90us/step - loss: 0.2128\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 86us/step - loss: 0.2031\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 90us/step - loss: 0.2036\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 90us/step - loss: 0.2172\n",
      "Generating from seed: so alice v\n",
      "so alice ventured to taste it, and found that it led into a small pees as. too the chupent’dl shemp!ne si f rn\n",
      "==================================================\n",
      "Iteration #: 28\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 91us/step - loss: 0.2050\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 87us/step - loss: 0.1998\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 87us/step - loss: 0.2003\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 86us/step - loss: 0.2012\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 87us/step - loss: 0.2100\n",
      "Generating from seed:  what is t\n",
      " what is the use of a bookea toun aromhe mi withand souddong oo sto seratlink tougr dow nity aitellle i souglt\n",
      "==================================================\n",
      "Iteration #: 29\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 87us/step - loss: 0.1971\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 86us/step - loss: 0.2049\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 92us/step - loss: 0.2094\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 89us/step - loss: 0.2092\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 89us/step - loss: 0.1924\n",
      "Generating from seed:  same size\n",
      " same size: to be sure, this generally gave herself very good oppoptiot make fot chow shept; and soushed fan t\n",
      "==================================================\n",
      "Iteration #: 30\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 85us/step - loss: 0.1942\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 91us/step - loss: 0.1829\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 88us/step - loss: 0.1835\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 87us/step - loss: 0.1880\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 86us/step - loss: 0.1875\n",
      "Generating from seed: ithout pic\n",
      "ithout pictures or conversations in it, ‘and what in the ingheres the shendre macacl, ong thas copllenusting! \n",
      "==================================================\n",
      "Iteration #: 31\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 88us/step - loss: 0.1871\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 88us/step - loss: 0.1893\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 88us/step - loss: 0.1882\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 90us/step - loss: 0.1878\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 96us/step - loss: 0.1814\n",
      "Generating from seed: wise littl\n",
      "wise little alice was not a mice to tor at, in thit; a soond in ay it eas gemplereels ea keat chas ick laid de\n",
      "==================================================\n",
      "Iteration #: 32\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 94us/step - loss: 0.1867\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 91us/step - loss: 0.1833\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 88us/step - loss: 0.1966\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 87us/step - loss: 0.2008\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 90us/step - loss: 0.1862\n",
      "Generating from seed: lice had n\n",
      "lice had not noticed before, and behind it when she wert lacplead thatry wayon thase har the somplesrede!?’ (a\n",
      "==================================================\n",
      "Iteration #: 33\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 90us/step - loss: 0.1791\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 90us/step - loss: 0.1836\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 89us/step - loss: 0.1854\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 93us/step - loss: 0.1704\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 89us/step - loss: 0.1785\n",
      "Generating from seed: shall thin\n",
      "shall think reedone ou byi fout was avery d thon lisely ig to bok oo her amich la the wnyen se me sould, tha k\n",
      "==================================================\n",
      "Iteration #: 34\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 90us/step - loss: 0.1800\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 93us/step - loss: 0.1739\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 89us/step - loss: 0.1857\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 88us/step - loss: 0.1909\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 95us/step - loss: 0.1841\n",
      "Generating from seed:  do cats e\n",
      " do cats eat bats?’ and sometimes, ‘do bats eat cats?’ for, you see, so many out-of-the-way things to hear of \n",
      "==================================================\n",
      "Iteration #: 35\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 92us/step - loss: 0.1804\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 92us/step - loss: 0.1740\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 93us/step - loss: 0.1729\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 94us/step - loss: 0.1652\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 97us/step - loss: 0.1667\n",
      "Generating from seed: o to ask: \n",
      "o to ask: per ats every sher offcersabbet, in t oo no der fongh sal tiok shea shaplind ,adinst ana latp on so \n",
      "==================================================\n",
      "Iteration #: 36\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 103us/step - loss: 0.1684\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 92us/step - loss: 0.1709\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 92us/step - loss: 0.1809\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 90us/step - loss: 0.1840\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 93us/step - loss: 0.1772\n",
      "Generating from seed: found she \n",
      "found she could not possibly reach it: she could not possibly reach it: she could not possibly reach it: she c\n",
      "==================================================\n",
      "Iteration #: 37\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 95us/step - loss: 0.1753\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 90us/step - loss: 0.1658\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 94us/step - loss: 0.1690\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 90us/step - loss: 0.1600\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 93us/step - loss: 0.1551\n",
      "Generating from seed:  she fell \n",
      " she fell very slowly, for she had poppee aft warely as eg ont heveny heve fouling thet io hor inl chelo de th\n",
      "==================================================\n",
      "Iteration #: 38\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 91us/step - loss: 0.1636\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 95us/step - loss: 0.1680\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 91us/step - loss: 0.1654\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11185/11185 [==============================] - 1s 87us/step - loss: 0.1755\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 88us/step - loss: 0.1701\n",
      "Generating from seed: was too sm\n",
      "was too smuppernust me sith rsinllene it’mi hernkend bof th fure she had plenty of time as she wes got anit fe\n",
      "==================================================\n",
      "Iteration #: 39\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 91us/step - loss: 0.1669\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 90us/step - loss: 0.1720\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 95us/step - loss: 0.1613\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 91us/step - loss: 0.1577\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 90us/step - loss: 0.1626\n",
      "Generating from seed: s marked “\n",
      "s marked “poison” or not’; for she had read several nice little histories about children who had got burnt, an\n",
      "==================================================\n",
      "Iteration #: 40\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 89us/step - loss: 0.1690\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 88us/step - loss: 0.1662\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 90us/step - loss: 0.1601\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 91us/step - loss: 0.1566\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 92us/step - loss: 0.1520\n",
      "Generating from seed: you to lea\n",
      "you to leave off this minute!’ she generally gave herself very good opportunity for showing off her knowledge,\n",
      "==================================================\n",
      "Iteration #: 41\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 93us/step - loss: 0.1563\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 88us/step - loss: 0.1492\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 89us/step - loss: 0.1602\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 88us/step - loss: 0.1496\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 87us/step - loss: 0.1691\n",
      "Generating from seed: d opportun\n",
      "d opportunity for showing off her knowledge, as there was no one to listenito, bhitely ubroa s mementertedong \n",
      "==================================================\n",
      "Iteration #: 42\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 91us/step - loss: 0.1640\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 86us/step - loss: 0.1600\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 86us/step - loss: 0.1593\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 86us/step - loss: 0.1626\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 87us/step - loss: 0.1657\n",
      "Generating from seed: ticed befo\n",
      "ticed before, and behind it was a little bottle on it, [‘which certainly was not here before,’ said alice, ‘an\n",
      "==================================================\n",
      "Iteration #: 43\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 87us/step - loss: 0.1709\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 87us/step - loss: 0.1685\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 90us/step - loss: 0.1760\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 88us/step - loss: 0.1530\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 89us/step - loss: 0.1501\n",
      "Generating from seed:  there was\n",
      " there was nothing so very remarkable was wothin waid she was to get out again. the rabbit was no longer to be\n",
      "==================================================\n",
      "Iteration #: 44\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 91us/step - loss: 0.1552\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 86us/step - loss: 0.1515\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 86us/step - loss: 0.1588\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 88us/step - loss: 0.1690\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 87us/step - loss: 0.1768\n",
      "Generating from seed:  (she was \n",
      " (she was rather glad there was not marked ‘poison,’ it is almost certain to disagree with you, sooner or late\n",
      "==================================================\n",
      "Iteration #: 45\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 89us/step - loss: 0.1562\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 89us/step - loss: 0.1379\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 87us/step - loss: 0.1394\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 90us/step - loss: 0.1477\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 92us/step - loss: 0.1516\n",
      "Generating from seed:  eat a bat\n",
      " eat a bat io the little golden key, and when she thought they were filled with cuploarshem is mi’s cout aid s\n",
      "==================================================\n",
      "Iteration #: 46\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 94us/step - loss: 0.1560\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 92us/step - loss: 0.1465\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 93us/step - loss: 0.1460\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 88us/step - loss: 0.1422\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 93us/step - loss: 0.1529\n",
      "Generating from seed:  was very \n",
      " was very fond of pretending to be two people. ‘but it’s no use in crying like that!’ said alice think it so v\n",
      "==================================================\n",
      "Iteration #: 47\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 94us/step - loss: 0.1566\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 90us/step - loss: 0.1453\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 90us/step - loss: 0.1535\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 93us/step - loss: 0.1839\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 89us/step - loss: 0.1559\n",
      "Generating from seed: ainly thro\n",
      "ainly through the glass, and she was quite surprised to find that she was coming to, but it was too smigherfel\n",
      "==================================================\n",
      "Iteration #: 48\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 94us/step - loss: 0.1452\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 91us/step - loss: 0.1462\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 97us/step - loss: 0.1535\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 96us/step - loss: 0.1621\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 88us/step - loss: 0.1521\n",
      "Generating from seed: ing how sh\n",
      "ing how she was elline to thite! thund touge to sitter, and thong inee howhed wath whichellengher gounet oa he\n",
      "==================================================\n",
      "Iteration #: 49\n",
      "Epoch 1/5\n",
      "11185/11185 [==============================] - 1s 89us/step - loss: 0.1559\n",
      "Epoch 2/5\n",
      "11185/11185 [==============================] - 1s 96us/step - loss: 0.1508\n",
      "Epoch 3/5\n",
      "11185/11185 [==============================] - 1s 94us/step - loss: 0.1519\n",
      "Epoch 4/5\n",
      "11185/11185 [==============================] - 1s 98us/step - loss: 0.1541\n",
      "Epoch 5/5\n",
      "11185/11185 [==============================] - 1s 95us/step - loss: 0.1551\n",
      "Generating from seed: under the \n",
      "under the door; so either way i’ll get into th a very sooplo thime thour-ofglingsthit derind of hald wats e wo\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(num_iterations):\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Iteration #: %d\" % (iteration))\n",
    "    model.fit(X_data, y_data, batch_size = batch_size, epochs = num_epochs)\n",
    "    \n",
    "    ## Test\n",
    "    test_idx = np.random.randint(len(input_chars))\n",
    "    test_chars = input_chars[test_idx]\n",
    "    print(\"Generating from seed: %s\" % (test_chars))\n",
    "    \n",
    "    print(test_chars, end=\"\")\n",
    "    for i in range(num_preds):\n",
    "        Xtest = np.zeros((1, seq_len, num_chars))\n",
    "        for j, ch in enumerate(test_chars):\n",
    "            Xtest[0, j, char2idx[ch]] = 1\n",
    "        pred = model.predict(Xtest, verbose = 0)[0]\n",
    "        ypred = idx2char[np.argmax(pred)]\n",
    "        print(ypred, end=\"\")\n",
    "        test_chars = test_chars[1:] + ypred\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
